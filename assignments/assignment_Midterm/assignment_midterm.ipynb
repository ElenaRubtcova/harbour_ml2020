{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-86e0de040aac317a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Midterm test and practice session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Questions.\n",
    "Please, answer the following questions briefly. Two or three sentences with main idea would be enough.\n",
    "\n",
    "Do not use external resourses in this part, please. Answer with you own words. If you forgot something, don't worry, we will discuss it later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0. \n",
    "Please, formulate the supervised learning problem statement.\n",
    "\n",
    "_Your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.\n",
    "\n",
    "What are regression and classification problems. Whatâ€™s the difference?\n",
    "\n",
    "_Your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.\n",
    "Write down the linear model for regression problem in matrix notation. What is Mean Squared Error (MSE) loss function? How can it be expressed?\n",
    "\n",
    "_Your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.\n",
    "What is the gradient of a function? How is it being used in optimization?\n",
    "\n",
    "_Your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.\n",
    "Write down gradient descent step for linear model and MSE for one-dimensional case.\n",
    "\n",
    "_Your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.\n",
    "What is validation? Cross validation?\n",
    "\n",
    "_Your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6.\n",
    "What is regularization? How does L1 regularization differ from L2 for linear models?\n",
    "\n",
    "_Your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7.\n",
    "What are precision and recall metrics?\n",
    "\n",
    "_Your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.8.\n",
    "What is bagging? What is the main idea beneath it?\n",
    "\n",
    "_Your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-be844269be69c387",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 2. Tackling Machine Learning problems in the wild\n",
    "Now you will work with real data in classification problem. Your goal it to solve (with some quality) and make some conclusions. It's quite similar to the `assignment0_02`. \n",
    "\n",
    "You may use external resources here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b656a4266174b009",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.0 Reading the data\n",
    "Today we work with the [dataset](https://archive.ics.uci.edu/ml/datasets/Statlog+%28Vehicle+Silhouettes%29), describing different cars for multiclass ($k=4$) classification problem. The data is available below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If on colab, uncomment the following lines\n",
    "\n",
    "# !wget https://raw.githubusercontent.com/neychev/harbour_ml2020/master/assignments/assignment_Midterm/car_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eebac6bfdf73d0bc",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(846, 19) (846,)\n",
      "(549, 19) (549,) (297, 19) (297,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = pd.read_csv('car_data.csv', delimiter=',', header=None).values\n",
    "data = dataset[:, :-1].astype(int)\n",
    "target = dataset[:, -1]\n",
    "\n",
    "print(data.shape, target.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.35)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-88b1a0f688568f2c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "To get some insights about the dataset, `pandas` might be used. The `train` part is transformed to `pd.DataFrame` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>494</td>\n",
       "      <td>106</td>\n",
       "      <td>54</td>\n",
       "      <td>105</td>\n",
       "      <td>164</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>247</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>165</td>\n",
       "      <td>269</td>\n",
       "      <td>891</td>\n",
       "      <td>243</td>\n",
       "      <td>84</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>317</td>\n",
       "      <td>95</td>\n",
       "      <td>45</td>\n",
       "      <td>105</td>\n",
       "      <td>208</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>187</td>\n",
       "      <td>36</td>\n",
       "      <td>22</td>\n",
       "      <td>150</td>\n",
       "      <td>202</td>\n",
       "      <td>520</td>\n",
       "      <td>158</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>198</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>701</td>\n",
       "      <td>108</td>\n",
       "      <td>49</td>\n",
       "      <td>103</td>\n",
       "      <td>200</td>\n",
       "      <td>62</td>\n",
       "      <td>10</td>\n",
       "      <td>206</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>155</td>\n",
       "      <td>227</td>\n",
       "      <td>635</td>\n",
       "      <td>215</td>\n",
       "      <td>72</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>189</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>515</td>\n",
       "      <td>76</td>\n",
       "      <td>38</td>\n",
       "      <td>58</td>\n",
       "      <td>125</td>\n",
       "      <td>58</td>\n",
       "      <td>5</td>\n",
       "      <td>133</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>127</td>\n",
       "      <td>152</td>\n",
       "      <td>259</td>\n",
       "      <td>145</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>177</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>543</td>\n",
       "      <td>96</td>\n",
       "      <td>37</td>\n",
       "      <td>74</td>\n",
       "      <td>187</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>159</td>\n",
       "      <td>42</td>\n",
       "      <td>20</td>\n",
       "      <td>134</td>\n",
       "      <td>183</td>\n",
       "      <td>378</td>\n",
       "      <td>134</td>\n",
       "      <td>69</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>190</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>179</td>\n",
       "      <td>89</td>\n",
       "      <td>44</td>\n",
       "      <td>70</td>\n",
       "      <td>137</td>\n",
       "      <td>58</td>\n",
       "      <td>6</td>\n",
       "      <td>136</td>\n",
       "      <td>49</td>\n",
       "      <td>18</td>\n",
       "      <td>146</td>\n",
       "      <td>168</td>\n",
       "      <td>273</td>\n",
       "      <td>166</td>\n",
       "      <td>78</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>423</td>\n",
       "      <td>85</td>\n",
       "      <td>45</td>\n",
       "      <td>70</td>\n",
       "      <td>120</td>\n",
       "      <td>54</td>\n",
       "      <td>7</td>\n",
       "      <td>149</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>145</td>\n",
       "      <td>169</td>\n",
       "      <td>326</td>\n",
       "      <td>186</td>\n",
       "      <td>81</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>181</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16</td>\n",
       "      <td>89</td>\n",
       "      <td>36</td>\n",
       "      <td>51</td>\n",
       "      <td>109</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>118</td>\n",
       "      <td>57</td>\n",
       "      <td>17</td>\n",
       "      <td>129</td>\n",
       "      <td>137</td>\n",
       "      <td>206</td>\n",
       "      <td>125</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>181</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>349</td>\n",
       "      <td>89</td>\n",
       "      <td>40</td>\n",
       "      <td>69</td>\n",
       "      <td>147</td>\n",
       "      <td>58</td>\n",
       "      <td>6</td>\n",
       "      <td>132</td>\n",
       "      <td>50</td>\n",
       "      <td>18</td>\n",
       "      <td>137</td>\n",
       "      <td>155</td>\n",
       "      <td>260</td>\n",
       "      <td>151</td>\n",
       "      <td>61</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>203</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>316</td>\n",
       "      <td>91</td>\n",
       "      <td>41</td>\n",
       "      <td>66</td>\n",
       "      <td>131</td>\n",
       "      <td>56</td>\n",
       "      <td>9</td>\n",
       "      <td>126</td>\n",
       "      <td>53</td>\n",
       "      <td>18</td>\n",
       "      <td>144</td>\n",
       "      <td>159</td>\n",
       "      <td>237</td>\n",
       "      <td>155</td>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>191</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>778</td>\n",
       "      <td>111</td>\n",
       "      <td>50</td>\n",
       "      <td>103</td>\n",
       "      <td>199</td>\n",
       "      <td>60</td>\n",
       "      <td>11</td>\n",
       "      <td>211</td>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>156</td>\n",
       "      <td>223</td>\n",
       "      <td>663</td>\n",
       "      <td>188</td>\n",
       "      <td>68</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>190</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>274</td>\n",
       "      <td>107</td>\n",
       "      <td>57</td>\n",
       "      <td>106</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>8</td>\n",
       "      <td>257</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>172</td>\n",
       "      <td>275</td>\n",
       "      <td>954</td>\n",
       "      <td>232</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>181</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>43</td>\n",
       "      <td>93</td>\n",
       "      <td>37</td>\n",
       "      <td>76</td>\n",
       "      <td>183</td>\n",
       "      <td>63</td>\n",
       "      <td>8</td>\n",
       "      <td>164</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>134</td>\n",
       "      <td>191</td>\n",
       "      <td>405</td>\n",
       "      <td>139</td>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>192</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>206</td>\n",
       "      <td>92</td>\n",
       "      <td>46</td>\n",
       "      <td>79</td>\n",
       "      <td>176</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>162</td>\n",
       "      <td>41</td>\n",
       "      <td>20</td>\n",
       "      <td>149</td>\n",
       "      <td>183</td>\n",
       "      <td>396</td>\n",
       "      <td>178</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>191</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>595</td>\n",
       "      <td>89</td>\n",
       "      <td>50</td>\n",
       "      <td>83</td>\n",
       "      <td>195</td>\n",
       "      <td>65</td>\n",
       "      <td>6</td>\n",
       "      <td>178</td>\n",
       "      <td>37</td>\n",
       "      <td>21</td>\n",
       "      <td>156</td>\n",
       "      <td>207</td>\n",
       "      <td>481</td>\n",
       "      <td>210</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>189</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1   2    3    4   5   6    7   8   9   10   11   12   13  14  15  \\\n",
       "0   494  106  54  105  164  48   5  247  27  27  165  269  891  243  84  12   \n",
       "1   317   95  45  105  208  64  10  187  36  22  150  202  520  158  64   7   \n",
       "2   701  108  49  103  200  62  10  206  32  23  155  227  635  215  72   6   \n",
       "3   515   76  38   58  125  58   5  133  51  18  127  152  259  145  87   0   \n",
       "4   543   96  37   74  187  68   8  159  42  20  134  183  378  134  69   3   \n",
       "5   179   89  44   70  137  58   6  136  49  18  146  168  273  166  78  10   \n",
       "6   423   85  45   70  120  54   7  149  45  19  145  169  326  186  81   8   \n",
       "7    16   89  36   51  109  52   6  118  57  17  129  137  206  125  80   2   \n",
       "8   349   89  40   69  147  58   6  132  50  18  137  155  260  151  61  16   \n",
       "9   316   91  41   66  131  56   9  126  53  18  144  159  237  155  72   3   \n",
       "10  778  111  50  103  199  60  11  211  31  24  156  223  663  188  68   9   \n",
       "11  274  107  57  106  179  51   8  257  26  28  172  275  954  232  83   2   \n",
       "12   43   93  37   76  183  63   8  164  40  20  134  191  405  139  67   4   \n",
       "13  206   92  46   79  176  64   8  162  41  20  149  183  396  178  67   2   \n",
       "14  595   89  50   83  195  65   6  178  37  21  156  207  481  210  71   1   \n",
       "\n",
       "    16   17   18  \n",
       "0    1  181  182  \n",
       "1   32  198  211  \n",
       "2   16  189  198  \n",
       "3   21  177  184  \n",
       "4   16  190  197  \n",
       "5    3  186  187  \n",
       "6    4  181  184  \n",
       "7   14  181  185  \n",
       "8    6  203  209  \n",
       "9   10  191  194  \n",
       "10   9  190  200  \n",
       "11  20  181  184  \n",
       "12   7  192  197  \n",
       "13  10  191  198  \n",
       "14   6  189  194  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pd = pd.DataFrame(X_train)\n",
    "\n",
    "# First 15 rows of our dataset.\n",
    "X_train_pd.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-98e7d91d77d65fcf",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Methods `describe` and `info` deliver some useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>431.415301</td>\n",
       "      <td>93.626594</td>\n",
       "      <td>44.686703</td>\n",
       "      <td>81.912568</td>\n",
       "      <td>169.384335</td>\n",
       "      <td>61.781421</td>\n",
       "      <td>8.506375</td>\n",
       "      <td>168.402550</td>\n",
       "      <td>40.979964</td>\n",
       "      <td>20.546448</td>\n",
       "      <td>147.637523</td>\n",
       "      <td>188.085610</td>\n",
       "      <td>437.526412</td>\n",
       "      <td>173.486339</td>\n",
       "      <td>71.941712</td>\n",
       "      <td>6.275046</td>\n",
       "      <td>12.841530</td>\n",
       "      <td>189.275046</td>\n",
       "      <td>196.140255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>248.783681</td>\n",
       "      <td>8.302718</td>\n",
       "      <td>6.271549</td>\n",
       "      <td>15.338861</td>\n",
       "      <td>32.913454</td>\n",
       "      <td>7.520018</td>\n",
       "      <td>4.232139</td>\n",
       "      <td>32.998066</td>\n",
       "      <td>7.698561</td>\n",
       "      <td>2.582954</td>\n",
       "      <td>14.711636</td>\n",
       "      <td>30.950307</td>\n",
       "      <td>175.509794</td>\n",
       "      <td>33.324033</td>\n",
       "      <td>7.063081</td>\n",
       "      <td>4.913015</td>\n",
       "      <td>9.022803</td>\n",
       "      <td>6.258347</td>\n",
       "      <td>7.362635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>181.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>209.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>441.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>363.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>197.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>639.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>575.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>201.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>845.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>288.000000</td>\n",
       "      <td>998.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>211.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  549.000000  549.000000  549.000000  549.000000  549.000000  549.000000   \n",
       "mean   431.415301   93.626594   44.686703   81.912568  169.384335   61.781421   \n",
       "std    248.783681    8.302718    6.271549   15.338861   32.913454    7.520018   \n",
       "min      0.000000   76.000000   33.000000   44.000000  104.000000   47.000000   \n",
       "25%    209.000000   87.000000   40.000000   70.000000  142.000000   57.000000   \n",
       "50%    441.000000   92.000000   44.000000   79.000000  166.000000   61.000000   \n",
       "75%    639.000000  100.000000   49.000000   96.000000  195.000000   65.000000   \n",
       "max    845.000000  119.000000   59.000000  110.000000  322.000000  133.000000   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  549.000000  549.000000  549.000000  549.000000  549.000000  549.000000   \n",
       "mean     8.506375  168.402550   40.979964   20.546448  147.637523  188.085610   \n",
       "std      4.232139   32.998066    7.698561    2.582954   14.711636   30.950307   \n",
       "min      2.000000  114.000000   26.000000   17.000000  118.000000  134.000000   \n",
       "25%      7.000000  146.000000   34.000000   19.000000  136.000000  167.000000   \n",
       "50%      8.000000  157.000000   43.000000   20.000000  145.000000  177.000000   \n",
       "75%     10.000000  196.000000   46.000000   23.000000  159.000000  216.000000   \n",
       "max     55.000000  262.000000   59.000000   28.000000  188.000000  288.000000   \n",
       "\n",
       "               12          13          14          15          16          17  \\\n",
       "count  549.000000  549.000000  549.000000  549.000000  549.000000  549.000000   \n",
       "mean   437.526412  173.486339   71.941712    6.275046   12.841530  189.275046   \n",
       "std    175.509794   33.324033    7.063081    4.913015    9.022803    6.258347   \n",
       "min    193.000000  109.000000   59.000000    0.000000    0.000000  176.000000   \n",
       "25%    318.000000  148.000000   67.000000    2.000000    6.000000  185.000000   \n",
       "50%    363.000000  172.000000   71.000000    5.000000   11.000000  189.000000   \n",
       "75%    575.000000  198.000000   75.000000    9.000000   19.000000  194.000000   \n",
       "max    998.000000  268.000000  119.000000   22.000000   41.000000  206.000000   \n",
       "\n",
       "               18  \n",
       "count  549.000000  \n",
       "mean   196.140255  \n",
       "std      7.362635  \n",
       "min    181.000000  \n",
       "25%    191.000000  \n",
       "50%    197.000000  \n",
       "75%    201.000000  \n",
       "max    211.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bus', 'opel', 'saab', 'van'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 549 entries, 0 to 548\n",
      "Data columns (total 19 columns):\n",
      "0     549 non-null int64\n",
      "1     549 non-null int64\n",
      "2     549 non-null int64\n",
      "3     549 non-null int64\n",
      "4     549 non-null int64\n",
      "5     549 non-null int64\n",
      "6     549 non-null int64\n",
      "7     549 non-null int64\n",
      "8     549 non-null int64\n",
      "9     549 non-null int64\n",
      "10    549 non-null int64\n",
      "11    549 non-null int64\n",
      "12    549 non-null int64\n",
      "13    549 non-null int64\n",
      "14    549 non-null int64\n",
      "15    549 non-null int64\n",
      "16    549 non-null int64\n",
      "17    549 non-null int64\n",
      "18    549 non-null int64\n",
      "dtypes: int64(19)\n",
      "memory usage: 81.6 KB\n"
     ]
    }
   ],
   "source": [
    "X_train_pd.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Data preprocessing\n",
    "* Make some transformations of the dataset (if necessary). Briefly explain the transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a1514aa189a49fca",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. PCA: explained variance plot\n",
    "* Apply the PCA to the train part of the data. Build the explaided variance plot (like in assignment 2). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1dd5ad5d0845cbbb",
     "locked": false,
     "points": 5,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0c1fe666f52fe53c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.3. PCA trasformation\n",
    "* Select the appropriate number of components. Use `fit` and `transform` methods to transform the `train` and `test` parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c6c614740bce090e",
     "locked": false,
     "points": 10,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4. Logistic regression\n",
    "* Find the optimal hyperparameters for logistic regression using cross-validation (e.g. `GridSearchCV`). You can vary only a parameter for `l2` regularization (e.g 5 different values).\n",
    "\n",
    "* Then build a ROC curve for this classifier (`sklearn.metrics.roc_curve`). Estimate the model quality with appropriate metrics (which will you use?)\n",
    "\n",
    "_Note: be careful with preprocessing (like scaling/PCA) to avoid data leaks._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-96ab18d96473ef71",
     "locked": false,
     "points": 5,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4fbf16c64076e139",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.5. Decision tree\n",
    "* Now train a desicion tree on the same data. Find optimal tree depth (`max_depth`) using cross-validation (again, checking 5 variants would be fine).\n",
    "\n",
    "* Measure the model quality using the same metrics you used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-748ed20b51c67fab",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-241b7691ab44cbfb",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.6. Random Forest\n",
    "Now we will work with the Random Forest (its `sklearn` implementation).\n",
    "\n",
    "* Vary the number of trees (from 5 to 50 with step 5) and build the plot in axes \"model accuracy\" - \"number of trees\".\n",
    "\n",
    "* What is the optimal number of trees you've got?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-888755d0f3d91620",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-99191c0852538d4d",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.7. Bonus part: \"learning curve\"\n",
    "* Split the training data into 10 equal (almost) parts. Then train the models from above (Logistic regression, Desicion Tree, Random Forest) with optimal hyperparameters you have selected on 1 part, 2 parts (combined, so the train size in increased by 2 times), 3 parts and so on.\n",
    "\n",
    "* Build a plot of accuracy and f1-score (on `test` part) varying the `train` dataset size (so the axes will be metric - dataset size.\n",
    "\n",
    "* Analyse the final plot. Can you make any conlusions using it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e39bc7e7dff61ff9",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Py3 research env",
   "language": "python",
   "name": "py3_research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
